# ==================== ISIC ROI SEGMENTASYON VE Ã–ZNÄ°TELÄ°K Ã‡IKARIMI ====================
# Mustafa Engin DalgÄ±Ã§ | 254309502
# ÃœskÃ¼dar Ãœniversitesi - Bilgisayar MÃ¼hendisliÄŸi YL
# Email: engindalgic86@gmail.com
#
# PROJE: ISIC 2018 Deri Lezyonu GÃ¶rÃ¼ntÃ¼lerinde ROI Segmentasyonu + Ã–znitelik Ã‡Ä±karÄ±mÄ±
# =====================================================================================

# ==================== KÃœTÃœPHANELER ====================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from PIL import Image
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# GÃ¶rselleÅŸtirme ayarlarÄ±
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['figure.dpi'] = 100

print("="*80)
print("ðŸ”¬ ISIC ROI SEGMENTASYON VE Ã–ZNÄ°TELÄ°K Ã‡IKARIMI")
print("="*80)
print("\nâœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!")
print(f"âœ… OpenCV versiyonu: {cv2.__version__}")
print(f"âœ… NumPy versiyonu: {np.__version__}")
print(f"âœ… Pandas versiyonu: {pd.__version__}")


# ==================== VERÄ° SETÄ° YÃœKLEME ====================
# ISIC klasÃ¶r yolunu buraya yazÄ±n:
# Ã–rnek Windows: r"C:\Users\ENGÄ°N\Desktop\ISIC"
# Ã–rnek Mac/Linux: "/home/engin/Desktop/ISIC"
DATA_PATH = "ISIC"  # AynÄ± klasÃ¶rde ise bÃ¶yle bÄ±rakÄ±n

def load_image_dataset(data_path):
    """
    ISIC klasÃ¶rÃ¼ndeki tÃ¼m gÃ¶rÃ¼ntÃ¼leri tarayÄ±p DataFrame'e yÃ¼kler
    
    Returns:
        pd.DataFrame: filename, filepath, width, height, class bilgilerini iÃ§eren DataFrame
    """
    print(f"\n{'='*80}")
    print("ðŸ“‚ VERÄ° SETÄ° YÃœKLEME")
    print("="*80)
    
    image_data = []
    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
    
    # ISIC klasÃ¶rÃ¼nÃ¼ tara
    for root, dirs, files in os.walk(data_path):
        for file in files:
            if file.lower().endswith(valid_extensions):
                file_path = os.path.join(root, file)
                
                # SÄ±nÄ±f bilgisi (klasÃ¶r adÄ±ndan)
                class_name = os.path.basename(root) if root != data_path else "unknown"
                
                try:
                    img = Image.open(file_path)
                    width, height = img.size
                    
                    image_data.append({
                        'filename': file,
                        'filepath': file_path,
                        'width': width,
                        'height': height,
                        'class': class_name,
                        'resolution': f"{width}x{height}"
                    })
                except Exception as e:
                    print(f"âš ï¸  Hata ({file}): {e}")
    
    df = pd.DataFrame(image_data)
    
    print(f"\nðŸ“Š Veri Seti Ä°statistikleri:")
    print(f"   Toplam gÃ¶rÃ¼ntÃ¼: {len(df)}")
    print(f"   SÄ±nÄ±f sayÄ±sÄ±: {df['class'].nunique()}")
    print(f"\nðŸ“‹ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    print(df['class'].value_counts())
    
    return df


# ==================== AÅžAMA 1: RGB â†’ GRAYSCALE DÃ–NÃœÅžÃœMÃœ ====================
def stage1_rgb_to_grayscale(df, num_samples=9, save_output=True):
    """
    AÅŸama 1: RGB gÃ¶rÃ¼ntÃ¼leri grayscale'e Ã§evir ve gÃ¶rselleÅŸtir
    
    Args:
        df: GÃ¶rÃ¼ntÃ¼ bilgilerini iÃ§eren DataFrame
        num_samples: GÃ¶rselleÅŸtirilecek rastgele Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: Grayscale gÃ¶rÃ¼ntÃ¼leri iÃ§eren dictionary
    """
    print(f"\n{'='*80}")
    print("ðŸŽ¨ AÅžAMA 1: RGB â†’ GRAYSCALE DÃ–NÃœÅžÃœMÃœ")
    print("="*80)
    
    # Rastgele Ã¶rnekler seÃ§
    np.random.seed(42)
    sample_indices = np.random.choice(df.index, size=min(num_samples, len(df)), replace=False)
    samples = df.iloc[sample_indices]
    
    # GÃ¶rselleÅŸtirme iÃ§in grid oluÅŸtur
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*2, figsize=(20, 12))
    fig.suptitle('AÅžAMA 1: RGB vs Grayscale KarÅŸÄ±laÅŸtÄ±rma', fontsize=16, fontweight='bold', y=0.995)
    
    grayscale_images = {}
    
    for idx, (i, row) in enumerate(samples.iterrows()):
        if idx >= rows * cols:
            break
            
        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
        img = cv2.imread(row['filepath'])
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Grayscale dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
        
        # Grayscale'i kaydet
        grayscale_images[row['filename']] = {
            'gray': img_gray,
            'rgb': img_rgb,
            'filepath': row['filepath'],
            'class': row['class']
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # RGB gÃ¶rÃ¼ntÃ¼ (sol)
        ax_rgb = axes[row_idx, col_idx*2]
        ax_rgb.imshow(img_rgb)
        ax_rgb.set_title(f'RGB\n{row["filename"][:20]}...\nClass: {row["class"]}', 
                         fontsize=9)
        ax_rgb.axis('off')
        
        # Grayscale gÃ¶rÃ¼ntÃ¼ (saÄŸ)
        ax_gray = axes[row_idx, col_idx*2 + 1]
        ax_gray.imshow(img_gray, cmap='gray')
        ax_gray.set_title(f'Grayscale\n{row["width"]}x{row["height"]}', 
                          fontsize=9)
        ax_gray.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '01_rgb_vs_grayscale.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… GÃ¶rselleÅŸtirme kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # Ä°statistikler
    print(f"\nðŸ“Š DÃ¶nÃ¼ÅŸÃ¼m Ä°statistikleri:")
    print(f"   Ä°ÅŸlenen gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±: {len(grayscale_images)}")
    print(f"   Ortalama boyut: {df['width'].mean():.0f} x {df['height'].mean():.0f} piksel")
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 1 TAMAMLANDI!")
    print("="*80)
    
    return grayscale_images


# ==================== AÅžAMA 2.1: DÄ°NAMÄ°K CROP ====================
def detect_background_threshold(img_gray):
    """
    Histogram analizi ile arka plan eÅŸik deÄŸerini belirle
    
    Args:
        img_gray: Grayscale gÃ¶rÃ¼ntÃ¼
        
    Returns:
        threshold: Arka plan iÃ§in eÅŸik deÄŸeri
    """
    # Histogram hesapla
    hist, bins = np.histogram(img_gray.flatten(), bins=256, range=[0, 256])
    
    # En yÃ¼ksek frekansa sahip piksel deÄŸeri (arka plan genelde en Ã§ok)
    # Genelde arka plan aÃ§Ä±k renk (yÃ¼ksek deÄŸer) olduÄŸundan Ã¼st yarÄ±yÄ± incele
    upper_half_hist = hist[128:]
    peak_idx = np.argmax(upper_half_hist) + 128
    
    # EÅŸik deÄŸeri: peak'in %80'i (arka plan genelde bu civarda)
    threshold = peak_idx * 0.8
    
    return threshold


def dynamic_crop(img_gray, margin=10):
    """
    Dinamik kÄ±rpma: Histogram analizi ile arka plan tespiti
    
    Strateji:
    1. Histogram analizi ile arka plan eÅŸik deÄŸerini bul
    2. Arka plan piksellerinin konumlarÄ±nÄ± tespit et
    3. Ä°lgi alanÄ±nÄ± (ROI) kapsayan minimum dikdÃ¶rtgeni bul
    4. Margin ekleyerek kÄ±rp
    
    Args:
        img_gray: Grayscale gÃ¶rÃ¼ntÃ¼
        margin: KÄ±rpma sonrasÄ± eklenecek boÅŸluk (piksel)
        
    Returns:
        cropped: KÄ±rpÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼
        crop_coords: KÄ±rpma koordinatlarÄ± (x1, y1, x2, y2)
    """
    h, w = img_gray.shape
    
    # Arka plan eÅŸiÄŸini belirle
    bg_threshold = detect_background_threshold(img_gray)
    
    # Arka plan olmayan (ilgi alanÄ±) piksellerini bul
    foreground_mask = img_gray < bg_threshold
    
    # Ä°lgi alanÄ±nÄ±n koordinatlarÄ±nÄ± bul
    rows = np.any(foreground_mask, axis=1)
    cols = np.any(foreground_mask, axis=0)
    
    if not np.any(rows) or not np.any(cols):
        # EÄŸer hiÃ§ ilgi alanÄ± tespit edilmediyse, orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ dÃ¶ndÃ¼r
        return img_gray, (0, 0, w, h)
    
    y1, y2 = np.where(rows)[0][[0, -1]]
    x1, x2 = np.where(cols)[0][[0, -1]]
    
    # Margin ekle (ama gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±rlarÄ±nÄ± aÅŸma)
    y1 = max(0, y1 - margin)
    y2 = min(h, y2 + margin)
    x1 = max(0, x1 - margin)
    x2 = min(w, x2 + margin)
    
    # KÄ±rp
    cropped = img_gray[y1:y2, x1:x2]
    
    return cropped, (x1, y1, x2, y2)


def stage2_1_dynamic_crop(grayscale_data, num_samples=9, save_output=True):
    """
    AÅŸama 2.1: Dinamik kÄ±rpma ile kenar gÃ¼rÃ¼ltÃ¼lerini temizle
    
    Args:
        grayscale_data: AÅŸama 1'den gelen grayscale gÃ¶rÃ¼ntÃ¼ dict'i
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: KÄ±rpÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼leri iÃ§eren dictionary
    """
    print(f"\n{'='*80}")
    print("âœ‚ï¸  AÅžAMA 2.1: DÄ°NAMÄ°K CROP (KIRPMA)")
    print("="*80)
    print("\nðŸ“‹ Strateji: Histogram analizi ile arka plan tespiti")
    print("   - Arka plan genelde aÃ§Ä±k renk (yÃ¼ksek piksel deÄŸeri)")
    print("   - Ä°lgi alanÄ± (lezyon) daha koyu (dÃ¼ÅŸÃ¼k piksel deÄŸeri)")
    print("   - Sadece ilgi alanÄ±nÄ± kapsayan bÃ¶lgeyi koru")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(grayscale_data.keys())[:num_samples]
    
    # GÃ¶rselleÅŸtirme iÃ§in grid oluÅŸtur
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*2, figsize=(20, 12))
    fig.suptitle('AÅžAMA 2.1: Dinamik Crop - Ã–ncesi vs SonrasÄ±', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    cropped_data = {}
    crop_stats = {
        'original_sizes': [],
        'cropped_sizes': [],
        'pixels_removed': [],
        'percent_removed': []
    }
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        img_gray = grayscale_data[key]['gray']
        original_h, original_w = img_gray.shape
        
        # Dinamik kÄ±rpma uygula
        cropped, (x1, y1, x2, y2) = dynamic_crop(img_gray, margin=10)
        cropped_h, cropped_w = cropped.shape
        
        # Ä°statistikleri kaydet
        original_pixels = original_h * original_w
        cropped_pixels = cropped_h * cropped_w
        removed_pixels = original_pixels - cropped_pixels
        percent_removed = (removed_pixels / original_pixels) * 100
        
        crop_stats['original_sizes'].append(f"{original_w}x{original_h}")
        crop_stats['cropped_sizes'].append(f"{cropped_w}x{cropped_h}")
        crop_stats['pixels_removed'].append(removed_pixels)
        crop_stats['percent_removed'].append(percent_removed)
        
        # Veriyi kaydet
        cropped_data[key] = {
            'cropped': cropped,
            'original': img_gray,
            'rgb': grayscale_data[key]['rgb'],
            'crop_coords': (x1, y1, x2, y2),
            'class': grayscale_data[key]['class'],
            'stats': {
                'original_size': (original_w, original_h),
                'cropped_size': (cropped_w, cropped_h),
                'removed_pixels': removed_pixels,
                'percent_removed': percent_removed
            }
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Orijinal (sol)
        ax_orig = axes[row_idx, col_idx*2]
        ax_orig.imshow(img_gray, cmap='gray')
        ax_orig.set_title(f'Orijinal\n{original_w}x{original_h}', fontsize=9)
        
        # KÄ±rpma bÃ¶lgesini Ã§iz
        from matplotlib.patches import Rectangle
        rect = Rectangle((x1, y1), x2-x1, y2-y1, 
                         linewidth=2, edgecolor='red', facecolor='none')
        ax_orig.add_patch(rect)
        ax_orig.axis('off')
        
        # KÄ±rpÄ±lmÄ±ÅŸ (saÄŸ)
        ax_crop = axes[row_idx, col_idx*2 + 1]
        ax_crop.imshow(cropped, cmap='gray')
        ax_crop.set_title(f'KÄ±rpÄ±lmÄ±ÅŸ\n{cropped_w}x{cropped_h}\nâ†“ %{percent_removed:.1f}', 
                          fontsize=9, color='green')
        ax_crop.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '02_dynamic_crop.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… GÃ¶rselleÅŸtirme kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # Ä°statistikler
    print(f"\nðŸ“Š KÄ±rpma Ä°statistikleri ({len(crop_stats['percent_removed'])} Ã¶rnek):")
    print(f"   Ortalama kÄ±rpÄ±lan alan: %{np.mean(crop_stats['percent_removed']):.1f}")
    print(f"   Min kÄ±rpÄ±lan alan: %{np.min(crop_stats['percent_removed']):.1f}")
    print(f"   Max kÄ±rpÄ±lan alan: %{np.max(crop_stats['percent_removed']):.1f}")
    
    print(f"\nðŸ’¡ YORUM:")
    avg_removed = np.mean(crop_stats['percent_removed'])
    if avg_removed < 10:
        print(f"   - KÄ±rpma oranÄ± dÃ¼ÅŸÃ¼k (%{avg_removed:.1f})")
        print(f"   - GÃ¶rÃ¼ntÃ¼lerde zaten az arka plan var")
        print(f"   - Lezyon merkeze yakÄ±n, iyi Ã§erÃ§evelenmiÅŸ")
    elif avg_removed < 30:
        print(f"   - KÄ±rpma oranÄ± orta (%{avg_removed:.1f})")
        print(f"   - Kenar gÃ¼rÃ¼ltÃ¼leri baÅŸarÄ±yla temizlendi")
        print(f"   - Ä°lgi alanÄ± korundu")
    else:
        print(f"   - KÄ±rpma oranÄ± yÃ¼ksek (%{avg_removed:.1f})")
        print(f"   - GÃ¶rÃ¼ntÃ¼lerde Ã§ok arka plan vardÄ±")
        print(f"   - Dinamik kÄ±rpma etkili oldu")
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 2.1 TAMAMLANDI!")
    print("="*80)
    
    return cropped_data


# ==================== AÅžAMA 2.2: KONTRAST Ä°YÄ°LEÅžTÄ°RME ====================
def contrast_stretching(img):
    """
    Kontrast germe (Min-Max normalizasyon)
    
    Args:
        img: Grayscale gÃ¶rÃ¼ntÃ¼
        
    Returns:
        img_stretched: Kontrast gerilmiÅŸ gÃ¶rÃ¼ntÃ¼
    """
    img_min = img.min()
    img_max = img.max()
    
    # EÄŸer gÃ¶rÃ¼ntÃ¼ zaten tam aralÄ±kta ise, olduÄŸu gibi dÃ¶ndÃ¼r
    if img_min == 0 and img_max == 255:
        return img
    
    # Min-Max normalizasyon
    img_stretched = ((img - img_min) / (img_max - img_min) * 255).astype(np.uint8)
    
    return img_stretched


def histogram_equalization(img):
    """
    Histogram eÅŸitleme
    
    Args:
        img: Grayscale gÃ¶rÃ¼ntÃ¼
        
    Returns:
        img_equalized: Histogram eÅŸitlenmiÅŸ gÃ¶rÃ¼ntÃ¼
    """
    img_equalized = cv2.equalizeHist(img)
    return img_equalized


def stage2_2_contrast_enhancement(cropped_data, num_samples=9, save_output=True):
    """
    AÅŸama 2.2: Kontrast iyileÅŸtirme - Stretching vs Equalization karÅŸÄ±laÅŸtÄ±rma
    
    Args:
        cropped_data: AÅŸama 2.1'den gelen kÄ±rpÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ dict'i
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: Kontrast iyileÅŸtirilmiÅŸ gÃ¶rÃ¼ntÃ¼leri iÃ§eren dictionary
    """
    print(f"\n{'='*80}")
    print("ðŸŽ¨ AÅžAMA 2.2: KONTRAST Ä°YÄ°LEÅžTÄ°RME")
    print("="*80)
    print("\nðŸ“‹ Ä°ki yÃ¶ntem test edilecek:")
    print("   A) Kontrast Germe (Stretching) - Min-Max normalizasyon")
    print("   B) Histogram EÅŸitleme (Equalization) - Histogram dÃ¼zleÅŸtirme")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(cropped_data.keys())[:num_samples]
    
    # 3 sÃ¼tunlu gÃ¶rselleÅŸtirme: Orijinal, Stretching, Equalization
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*3, figsize=(24, 12))
    fig.suptitle('AÅžAMA 2.2: Kontrast Ä°yileÅŸtirme KarÅŸÄ±laÅŸtÄ±rma', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    enhanced_data = {}
    comparison_stats = {
        'original_range': [],
        'stretched_range': [],
        'equalized_range': [],
        'original_std': [],
        'stretched_std': [],
        'equalized_std': []
    }
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        img_cropped = cropped_data[key]['cropped']
        
        # Her iki yÃ¶ntemi uygula
        img_stretched = contrast_stretching(img_cropped)
        img_equalized = histogram_equalization(img_cropped)
        
        # Ä°statistikleri kaydet
        comparison_stats['original_range'].append(img_cropped.max() - img_cropped.min())
        comparison_stats['stretched_range'].append(img_stretched.max() - img_stretched.min())
        comparison_stats['equalized_range'].append(img_equalized.max() - img_equalized.min())
        comparison_stats['original_std'].append(img_cropped.std())
        comparison_stats['stretched_std'].append(img_stretched.std())
        comparison_stats['equalized_std'].append(img_equalized.std())
        
        # Veriyi kaydet (her iki yÃ¶ntem de)
        enhanced_data[key] = {
            'cropped': img_cropped,
            'stretched': img_stretched,
            'equalized': img_equalized,
            'rgb': cropped_data[key]['rgb'],
            'class': cropped_data[key]['class'],
            'stats': {
                'original': {
                    'range': comparison_stats['original_range'][-1],
                    'std': comparison_stats['original_std'][-1],
                    'mean': img_cropped.mean()
                },
                'stretched': {
                    'range': comparison_stats['stretched_range'][-1],
                    'std': comparison_stats['stretched_std'][-1],
                    'mean': img_stretched.mean()
                },
                'equalized': {
                    'range': comparison_stats['equalized_range'][-1],
                    'std': comparison_stats['equalized_std'][-1],
                    'mean': img_equalized.mean()
                }
            }
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Orijinal (sol)
        ax_orig = axes[row_idx, col_idx*3]
        ax_orig.imshow(img_cropped, cmap='gray')
        ax_orig.set_title(f'Orijinal\nRange: {img_cropped.max()-img_cropped.min()}\nStd: {img_cropped.std():.1f}', 
                          fontsize=8)
        ax_orig.axis('off')
        
        # Stretching (orta)
        ax_stretch = axes[row_idx, col_idx*3 + 1]
        ax_stretch.imshow(img_stretched, cmap='gray')
        ax_stretch.set_title(f'Stretching\nRange: {img_stretched.max()-img_stretched.min()}\nStd: {img_stretched.std():.1f}', 
                            fontsize=8, color='blue')
        ax_stretch.axis('off')
        
        # Equalization (saÄŸ)
        ax_equal = axes[row_idx, col_idx*3 + 2]
        ax_equal.imshow(img_equalized, cmap='gray')
        ax_equal.set_title(f'Equalization\nRange: {img_equalized.max()-img_equalized.min()}\nStd: {img_equalized.std():.1f}', 
                          fontsize=8, color='green')
        ax_equal.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '03_contrast_comparison.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… KarÅŸÄ±laÅŸtÄ±rma kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # Histogram karÅŸÄ±laÅŸtÄ±rmasÄ± (detaylÄ±)
    fig2, axes2 = plt.subplots(3, 3, figsize=(15, 12))
    fig2.suptitle('AÅžAMA 2.2: Histogram Analizi (Ä°lk 9 Ã–rnek)', 
                  fontsize=14, fontweight='bold')
    
    for idx, key in enumerate(sample_keys[:9]):
        if idx >= 9:
            break
        
        img_cropped = cropped_data[key]['cropped']
        img_stretched = enhanced_data[key]['stretched']
        img_equalized = enhanced_data[key]['equalized']
        
        row_idx = idx // 3
        col_idx = idx % 3
        ax = axes2[row_idx, col_idx]
        
        # HistogramlarÄ± Ã§iz
        ax.hist(img_cropped.flatten(), bins=50, alpha=0.5, label='Orijinal', color='gray')
        ax.hist(img_stretched.flatten(), bins=50, alpha=0.5, label='Stretching', color='blue')
        ax.hist(img_equalized.flatten(), bins=50, alpha=0.5, label='Equalization', color='green')
        
        ax.set_title(f'Ã–rnek {idx+1}', fontsize=9)
        ax.set_xlabel('Piksel DeÄŸeri', fontsize=8)
        ax.set_ylabel('Frekans', fontsize=8)
        ax.legend(fontsize=7)
        ax.grid(alpha=0.3)
    
    plt.tight_layout()
    
    if save_output:
        output_file2 = '03_histogram_analysis.png'
        plt.savefig(output_file2, dpi=150, bbox_inches='tight')
        print(f"âœ… Histogram analizi kaydedildi: {output_file2}")
    
    plt.show()
    plt.close()
    
    # Ä°statistiksel karÅŸÄ±laÅŸtÄ±rma
    print(f"\nðŸ“Š Ä°statistiksel KarÅŸÄ±laÅŸtÄ±rma ({len(comparison_stats['original_range'])} Ã¶rnek):")
    print(f"\n   Piksel AralÄ±ÄŸÄ± (Range):")
    print(f"      Orijinal:     Ort: {np.mean(comparison_stats['original_range']):.1f}")
    print(f"      Stretching:   Ort: {np.mean(comparison_stats['stretched_range']):.1f} (+{np.mean(comparison_stats['stretched_range']) - np.mean(comparison_stats['original_range']):.1f})")
    print(f"      Equalization: Ort: {np.mean(comparison_stats['equalized_range']):.1f} (+{np.mean(comparison_stats['equalized_range']) - np.mean(comparison_stats['original_range']):.1f})")
    
    print(f"\n   Standart Sapma (Std - Kontrast gÃ¶stergesi):")
    print(f"      Orijinal:     Ort: {np.mean(comparison_stats['original_std']):.1f}")
    print(f"      Stretching:   Ort: {np.mean(comparison_stats['stretched_std']):.1f} (+{np.mean(comparison_stats['stretched_std']) - np.mean(comparison_stats['original_std']):.1f})")
    print(f"      Equalization: Ort: {np.mean(comparison_stats['equalized_std']):.1f} (+{np.mean(comparison_stats['equalized_std']) - np.mean(comparison_stats['original_std']):.1f})")
    
    # YÃ¶ntem Ã¶nerisi
    print(f"\nðŸ’¡ OTOMATÄ°K ANALÄ°Z:")
    avg_original_std = np.mean(comparison_stats['original_std'])
    avg_stretched_std = np.mean(comparison_stats['stretched_std'])
    avg_equalized_std = np.mean(comparison_stats['equalized_std'])
    
    stretch_improvement = avg_stretched_std - avg_original_std
    equal_improvement = avg_equalized_std - avg_original_std
    
    print(f"\n   Kontrast Ä°yileÅŸtirme MiktarÄ±:")
    print(f"      Stretching:   +{stretch_improvement:.1f} std")
    print(f"      Equalization: +{equal_improvement:.1f} std")
    
    if stretch_improvement < 5 and equal_improvement < 5:
        print(f"\n   âš ï¸  Her iki yÃ¶ntem de az iyileÅŸtirme saÄŸladÄ±")
        print(f"   â†’ GÃ¶rÃ¼ntÃ¼ler zaten iyi kontrasta sahip")
        print(f"   â†’ Orijinal gÃ¶rÃ¼ntÃ¼lerle devam edilebilir")
        recommendation = "original"
    elif stretch_improvement > equal_improvement * 1.2:
        print(f"\n   âœ… Ã–NERÄ°: STRETCHING")
        print(f"   â†’ Daha fazla kontrast iyileÅŸtirmesi (+{stretch_improvement:.1f})")
        print(f"   â†’ Histogram daha dengeli daÄŸÄ±lmÄ±ÅŸ")
        print(f"   â†’ Detay korumasÄ± daha iyi")
        recommendation = "stretching"
    elif equal_improvement > stretch_improvement * 1.2:
        print(f"\n   âœ… Ã–NERÄ°: EQUALIZATION")
        print(f"   â†’ Daha fazla kontrast iyileÅŸtirmesi (+{equal_improvement:.1f})")
        print(f"   â†’ Lezyon-arka plan ayrÄ±mÄ± daha net")
        print(f"   â†’ Segmentasyon iÃ§in daha uygun")
        recommendation = "equalization"
    else:
        print(f"\n   âš–ï¸  Her iki yÃ¶ntem de benzer performans")
        print(f"   â†’ Stretching: +{stretch_improvement:.1f} std")
        print(f"   â†’ Equalization: +{equal_improvement:.1f} std")
        print(f"   â†’ GÃ¶rsel kontrole gÃ¶re karar verilmeli")
        recommendation = "equalization"  # Segmentasyon iÃ§in genelde daha iyi
    
    # Ã–nerilen yÃ¶ntemi kaydet
    for key in enhanced_data:
        enhanced_data[key]['recommended'] = recommendation
        if recommendation == "stretching":
            enhanced_data[key]['selected'] = enhanced_data[key]['stretched']
        elif recommendation == "equalization":
            enhanced_data[key]['selected'] = enhanced_data[key]['equalized']
        else:  # original
            enhanced_data[key]['selected'] = enhanced_data[key]['cropped']
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 2.2 TAMAMLANDI!")
    print(f"ðŸ“Œ Otomatik Ã¶neri: {recommendation.upper()}")
    print("="*80)
    
    return enhanced_data, recommendation


# ==================== AÅžAMA 2.3: GÃœRÃœLTÃœ AZALTMA (MEDIAN BLUR) ====================
def stage2_3_noise_reduction(enhanced_data, kernel_sizes=[3, 5, 7], 
                              num_samples=9, save_output=True):
    """
    AÅŸama 2.3: Median Blur ile gÃ¼rÃ¼ltÃ¼ azaltma
    
    Median Blur:
    - Tuz-biber gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ mÃ¼kemmel temizler
    - Kenar korumasÄ± Ã§ok iyi (Gaussian'dan Ã¼stÃ¼n)
    - Non-linear filtre (outlier'lara dayanÄ±klÄ±)
    - Segmentasyon Ã¶ncesi ideal
    
    Args:
        enhanced_data: AÅŸama 2.2'den gelen kontrast iyileÅŸtirilmiÅŸ dict
        kernel_sizes: Test edilecek kernel boyutlarÄ± (tek sayÄ± olmalÄ±)
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: GÃ¼rÃ¼ltÃ¼ azaltÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼leri iÃ§eren dictionary
    """
    print(f"\n{'='*80}")
    print("ðŸ”‡ AÅžAMA 2.3: GÃœRÃœLTÃœ AZALTMA (MEDIAN BLUR)")
    print("="*80)
    print("\nðŸ“‹ Median Blur Ã–zellikleri:")
    print("   âœ… Tuz-biber gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ mÃ¼kemmel temizler")
    print("   âœ… Kenar korumasÄ± Ã§ok iyi (Gaussian'dan Ã¼stÃ¼n)")
    print("   âœ… Outlier'lara dayanÄ±klÄ± (non-linear)")
    print("   âœ… Segmentasyon iÃ§in ideal")
    print(f"\nðŸ”§ Test edilecek kernel boyutlarÄ±: {kernel_sizes}")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(enhanced_data.keys())[:num_samples]
    
    # GÃ¶rselleÅŸtirme: Orijinal + 3 farklÄ± kernel boyutu
    rows = 3
    cols = 3
    n_kernels = len(kernel_sizes)
    fig, axes = plt.subplots(rows, cols*(n_kernels+1), figsize=(6*(n_kernels+1), 12))
    fig.suptitle('AÅžAMA 2.3: Median Blur - Kernel Boyutu KarÅŸÄ±laÅŸtÄ±rma', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    blurred_data = {}
    blur_stats = {
        'original_std': [],
        'blur_std': {k: [] for k in kernel_sizes},
        'edge_preservation': {k: [] for k in kernel_sizes}
    }
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        # SeÃ§ilen (kontrast iyileÅŸtirilmiÅŸ) gÃ¶rÃ¼ntÃ¼yÃ¼ al
        img_enhanced = enhanced_data[key]['selected']
        
        # Her kernel boyutu iÃ§in median blur uygula
        blurred_versions = {}
        for ksize in kernel_sizes:
            img_blurred = cv2.medianBlur(img_enhanced, ksize)
            blurred_versions[ksize] = img_blurred
            
            # Ä°statistikleri kaydet
            blur_stats['blur_std'][ksize].append(img_blurred.std())
            
            # Kenar korumasÄ±: Laplacian varyansÄ± (yÃ¼ksek = daha fazla kenar)
            laplacian_orig = cv2.Laplacian(img_enhanced, cv2.CV_64F).var()
            laplacian_blur = cv2.Laplacian(img_blurred, cv2.CV_64F).var()
            edge_preservation_ratio = laplacian_blur / laplacian_orig if laplacian_orig > 0 else 0
            blur_stats['edge_preservation'][ksize].append(edge_preservation_ratio)
        
        blur_stats['original_std'].append(img_enhanced.std())
        
        # Veriyi kaydet
        blurred_data[key] = {
            'enhanced': img_enhanced,
            'blurred': blurred_versions,
            'rgb': enhanced_data[key]['rgb'],
            'class': enhanced_data[key]['class'],
            'stats': {
                'original_std': blur_stats['original_std'][-1],
                'blur_std': {k: blur_stats['blur_std'][k][-1] for k in kernel_sizes},
                'edge_preservation': {k: blur_stats['edge_preservation'][k][-1] for k in kernel_sizes}
            }
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Orijinal (en sol)
        ax_orig = axes[row_idx, col_idx*(n_kernels+1)]
        ax_orig.imshow(img_enhanced, cmap='gray')
        ax_orig.set_title(f'Kontrast Ä°yileÅŸtirilmiÅŸ\nStd: {img_enhanced.std():.1f}', 
                          fontsize=8)
        ax_orig.axis('off')
        
        # Her kernel boyutu
        for kidx, ksize in enumerate(kernel_sizes):
            img_blurred = blurred_versions[ksize]
            ax_blur = axes[row_idx, col_idx*(n_kernels+1) + kidx + 1]
            ax_blur.imshow(img_blurred, cmap='gray')
            
            # Kenar korumasÄ± yÃ¼zdesi
            edge_pres = blur_stats['edge_preservation'][ksize][-1] * 100
            color = 'green' if edge_pres > 85 else 'orange' if edge_pres > 70 else 'red'
            
            ax_blur.set_title(f'Kernel: {ksize}x{ksize}\nStd: {img_blurred.std():.1f}\nEdge: {edge_pres:.0f}%', 
                             fontsize=8, color=color)
            ax_blur.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '04_median_blur_comparison.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… KarÅŸÄ±laÅŸtÄ±rma kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # DetaylÄ± istatistikler
    print(f"\nðŸ“Š GÃ¼rÃ¼ltÃ¼ Azaltma Ä°statistikleri ({len(blur_stats['original_std'])} Ã¶rnek):")
    print(f"\n   Orijinal (Kontrast Ä°yileÅŸtirilmiÅŸ):")
    print(f"      Ortalama Std: {np.mean(blur_stats['original_std']):.1f}")
    
    for ksize in kernel_sizes:
        avg_std = np.mean(blur_stats['blur_std'][ksize])
        avg_edge = np.mean(blur_stats['edge_preservation'][ksize]) * 100
        std_change = avg_std - np.mean(blur_stats['original_std'])
        
        print(f"\n   Kernel {ksize}x{ksize}:")
        print(f"      Ortalama Std: {avg_std:.1f} ({std_change:+.1f})")
        print(f"      Kenar KorumasÄ±: {avg_edge:.1f}%")
    
    # Optimal kernel boyutunu belirle
    print(f"\nðŸ’¡ OTOMATÄ°K KERNEL SEÃ‡Ä°MÄ°:")
    
    kernel_scores = {}
    for ksize in kernel_sizes:
        # Skor: Kenar korumasÄ± aÄŸÄ±rlÄ±klÄ±
        avg_edge = np.mean(blur_stats['edge_preservation'][ksize])
        avg_std = np.mean(blur_stats['blur_std'][ksize])
        
        # Kenar korumasÄ± > 0.80 â†’ iyi (aÄŸÄ±rlÄ±k: 70%)
        # Std dÃ¼ÅŸmesi â†’ gÃ¼rÃ¼ltÃ¼ azaldÄ± (aÄŸÄ±rlÄ±k: 30%)
        edge_score = avg_edge
        noise_reduction_score = 1.0 - (avg_std / np.mean(blur_stats['original_std']))
        
        total_score = (edge_score * 0.7) + (noise_reduction_score * 0.3)
        kernel_scores[ksize] = total_score
    
    best_kernel = max(kernel_scores, key=kernel_scores.get)
    
    print(f"\n   Kernel SkorlarÄ±:")
    for ksize in kernel_sizes:
        score = kernel_scores[ksize]
        edge_pres = np.mean(blur_stats['edge_preservation'][ksize]) * 100
        marker = "â­ Ã–NERILEN" if ksize == best_kernel else ""
        print(f"      {ksize}x{ksize}: {score:.3f} (Kenar: {edge_pres:.1f}%) {marker}")
    
    print(f"\n   âœ… Ã–NERILEN KERNEL: {best_kernel}x{best_kernel}")
    
    # Yorum
    if best_kernel == 3:
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - KÃ¼Ã§Ã¼k kernel (3x3) â†’ minimal yumuÅŸatma")
        print(f"      - Kenar korumasÄ± mÃ¼kemmel")
        print(f"      - Hafif gÃ¼rÃ¼ltÃ¼ler temizlendi")
        print(f"      - Detay kaybÄ± yok")
    elif best_kernel == 5:
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - Orta kernel (5x5) â†’ dengeli yaklaÅŸÄ±m")
        print(f"      - Ä°yi kenar korumasÄ±")
        print(f"      - Orta seviye gÃ¼rÃ¼ltÃ¼ temizliÄŸi")
        print(f"      - Segmentasyon iÃ§in ideal")
    else:  # 7 veya daha bÃ¼yÃ¼k
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - BÃ¼yÃ¼k kernel ({best_kernel}x{best_kernel}) â†’ gÃ¼Ã§lÃ¼ yumuÅŸatma")
        print(f"      - AÄŸÄ±r gÃ¼rÃ¼ltÃ¼ler temizlendi")
        print(f"      - BazÄ± detay kaybÄ± olabilir")
        print(f"      - Ã‡ok gÃ¼rÃ¼ltÃ¼lÃ¼ gÃ¶rÃ¼ntÃ¼ler iÃ§in uygun")
    
    # SeÃ§ilen kernel ile final versiyonu oluÅŸtur
    for key in blurred_data:
        blurred_data[key]['selected_kernel'] = best_kernel
        blurred_data[key]['final'] = blurred_data[key]['blurred'][best_kernel]
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 2.3 TAMAMLANDI!")
    print(f"ðŸ“Œ SeÃ§ilen kernel: {best_kernel}x{best_kernel}")
    print("="*80)
    
    return blurred_data, best_kernel


# ==================== AÅžAMA 3: THRESHOLDING Ä°LE SEGMENTASYON ====================
def apply_global_threshold(img, threshold_value=127):
    """Global thresholding - Sabit eÅŸik deÄŸeri"""
    _, binary = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)
    return binary, threshold_value


def apply_otsu_threshold(img):
    """Otsu thresholding - Otomatik optimal eÅŸik"""
    threshold_value, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    return binary, threshold_value


def apply_adaptive_threshold(img, block_size=11, C=2):
    """Adaptive thresholding - Lokal adaptif eÅŸik"""
    binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY_INV, block_size, C)
    return binary, None  # Adaptive'de tek bir threshold deÄŸeri yok


def stage3_thresholding_segmentation(blurred_data, num_samples=9, save_output=True):
    """
    AÅŸama 3: Thresholding ile binary segmentasyon
    
    3 yÃ¶ntem test edilecek:
    1. Global Thresholding (Sabit eÅŸik)
    2. Otsu Thresholding (Otomatik optimal eÅŸik) - Ã–nerilen
    3. Adaptive Thresholding (Lokal adaptif)
    
    Args:
        blurred_data: AÅŸama 2.3'ten gelen yumuÅŸatÄ±lmÄ±ÅŸ dict
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: Binary maskeleri iÃ§eren dictionary
        str: Ã–nerilen yÃ¶ntem
    """
    print(f"\n{'='*80}")
    print("ðŸŽ­ AÅžAMA 3: THRESHOLDING Ä°LE SEGMENTASYON")
    print("="*80)
    print("\nðŸ“‹ 3 YÃ¶ntem Test Edilecek:")
    print("   1ï¸âƒ£  Global Thresholding - Sabit eÅŸik deÄŸeri (Ã¶rn. 127)")
    print("   2ï¸âƒ£  Otsu Thresholding - Otomatik optimal eÅŸik â­ Ã–NERÄ°LEN")
    print("   3ï¸âƒ£  Adaptive Thresholding - Lokal adaptif eÅŸik")
    print("\nðŸŽ¯ Hedef: Lezyon (beyaz) vs Arka plan (siyah) ayrÄ±mÄ±")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(blurred_data.keys())[:num_samples]
    
    # 4 sÃ¼tunlu gÃ¶rselleÅŸtirme: Orijinal + 3 yÃ¶ntem
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*4, figsize=(24, 12))
    fig.suptitle('AÅžAMA 3.1-3.2: Thresholding YÃ¶ntemleri KarÅŸÄ±laÅŸtÄ±rma', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    segmented_data = {}
    threshold_stats = {
        'global_threshold': 127,  # Sabit
        'otsu_thresholds': [],
        'roi_pixels_global': [],
        'roi_pixels_otsu': [],
        'roi_pixels_adaptive': []
    }
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        img_blurred = blurred_data[key]['final']
        
        # 3 yÃ¶ntemi uygula
        binary_global, threshold_global = apply_global_threshold(img_blurred, threshold_value=127)
        binary_otsu, threshold_otsu = apply_otsu_threshold(img_blurred)
        binary_adaptive, _ = apply_adaptive_threshold(img_blurred, block_size=11, C=2)
        
        # Ä°statistikleri kaydet
        threshold_stats['otsu_thresholds'].append(threshold_otsu)
        
        # ROI piksel sayÄ±sÄ± (beyaz pikseller)
        roi_global = np.sum(binary_global == 255)
        roi_otsu = np.sum(binary_otsu == 255)
        roi_adaptive = np.sum(binary_adaptive == 255)
        
        threshold_stats['roi_pixels_global'].append(roi_global)
        threshold_stats['roi_pixels_otsu'].append(roi_otsu)
        threshold_stats['roi_pixels_adaptive'].append(roi_adaptive)
        
        # Veriyi kaydet
        segmented_data[key] = {
            'blurred': img_blurred,
            'binary_global': binary_global,
            'binary_otsu': binary_otsu,
            'binary_adaptive': binary_adaptive,
            'threshold_global': threshold_global,
            'threshold_otsu': threshold_otsu,
            'rgb': blurred_data[key]['rgb'],
            'class': blurred_data[key]['class'],
            'stats': {
                'roi_pixels_global': roi_global,
                'roi_pixels_otsu': roi_otsu,
                'roi_pixels_adaptive': roi_adaptive
            }
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Orijinal yumuÅŸatÄ±lmÄ±ÅŸ (en sol)
        ax_orig = axes[row_idx, col_idx*4]
        ax_orig.imshow(img_blurred, cmap='gray')
        ax_orig.set_title(f'Blur SonrasÄ±', fontsize=8)
        ax_orig.axis('off')
        
        # Global Threshold
        ax_global = axes[row_idx, col_idx*4 + 1]
        ax_global.imshow(binary_global, cmap='gray')
        ax_global.set_title(f'Global (T={threshold_global})\nROI: {roi_global} px', 
                           fontsize=8, color='blue')
        ax_global.axis('off')
        
        # Otsu Threshold
        ax_otsu = axes[row_idx, col_idx*4 + 2]
        ax_otsu.imshow(binary_otsu, cmap='gray')
        ax_otsu.set_title(f'Otsu (T={threshold_otsu:.0f})\nROI: {roi_otsu} px', 
                         fontsize=8, color='green')
        ax_otsu.axis('off')
        
        # Adaptive Threshold
        ax_adaptive = axes[row_idx, col_idx*4 + 3]
        ax_adaptive.imshow(binary_adaptive, cmap='gray')
        ax_adaptive.set_title(f'Adaptive\nROI: {roi_adaptive} px', 
                             fontsize=8, color='orange')
        ax_adaptive.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '05_threshold_comparison.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… KarÅŸÄ±laÅŸtÄ±rma kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # EÅŸik deÄŸerleri analizi
    print(f"\nðŸ“Š EÅŸik DeÄŸeri Analizi ({len(threshold_stats['otsu_thresholds'])} Ã¶rnek):")
    print(f"\n   Global Thresholding:")
    print(f"      EÅŸik deÄŸeri: {threshold_stats['global_threshold']} (sabit)")
    print(f"      Ortalama ROI: {np.mean(threshold_stats['roi_pixels_global']):.0f} piksel")
    
    print(f"\n   Otsu Thresholding:")
    print(f"      Ortalama eÅŸik: {np.mean(threshold_stats['otsu_thresholds']):.1f}")
    print(f"      Min eÅŸik: {np.min(threshold_stats['otsu_thresholds']):.0f}")
    print(f"      Max eÅŸik: {np.max(threshold_stats['otsu_thresholds']):.0f}")
    print(f"      Ortalama ROI: {np.mean(threshold_stats['roi_pixels_otsu']):.0f} piksel")
    
    print(f"\n   Adaptive Thresholding:")
    print(f"      EÅŸik deÄŸeri: Lokal (gÃ¶rÃ¼ntÃ¼ bÃ¶lgelerine gÃ¶re deÄŸiÅŸir)")
    print(f"      Ortalama ROI: {np.mean(threshold_stats['roi_pixels_adaptive']):.0f} piksel")
    
    # YÃ¶ntem Ã¶nerisi
    print(f"\nðŸ’¡ OTOMATÄ°K YÃ–NTEM SEÃ‡Ä°MÄ°:")
    
    # ROI boyutlarÄ± karÅŸÄ±laÅŸtÄ±r
    avg_roi_global = np.mean(threshold_stats['roi_pixels_global'])
    avg_roi_otsu = np.mean(threshold_stats['roi_pixels_otsu'])
    avg_roi_adaptive = np.mean(threshold_stats['roi_pixels_adaptive'])
    
    # ROI tutarlÄ±lÄ±ÄŸÄ± (std deviation dÃ¼ÅŸÃ¼k = tutarlÄ±)
    std_roi_global = np.std(threshold_stats['roi_pixels_global'])
    std_roi_otsu = np.std(threshold_stats['roi_pixels_otsu'])
    std_roi_adaptive = np.std(threshold_stats['roi_pixels_adaptive'])
    
    # TutarlÄ±lÄ±k skoru (dÃ¼ÅŸÃ¼k std = yÃ¼ksek tutarlÄ±lÄ±k)
    consistency_global = 1.0 / (1.0 + std_roi_global / avg_roi_global)
    consistency_otsu = 1.0 / (1.0 + std_roi_otsu / avg_roi_otsu)
    consistency_adaptive = 1.0 / (1.0 + std_roi_adaptive / avg_roi_adaptive)
    
    print(f"\n   ROI TutarlÄ±lÄ±k Skoru (yÃ¼ksek = iyi):")
    print(f"      Global:   {consistency_global:.3f}")
    print(f"      Otsu:     {consistency_otsu:.3f}")
    print(f"      Adaptive: {consistency_adaptive:.3f}")
    
    # Otsu genelde en iyi (equalization sonrasÄ±)
    scores = {
        'global': consistency_global * 0.8,  # Sabit eÅŸik pek uygun deÄŸil
        'otsu': consistency_otsu * 1.0,      # Otsu ideal
        'adaptive': consistency_adaptive * 0.9  # Adaptive bazen aÅŸÄ±rÄ± hassas
    }
    
    best_method = max(scores, key=scores.get)
    
    print(f"\n   Toplam Skorlar:")
    for method, score in scores.items():
        marker = "â­ Ã–NERÄ°LEN" if method == best_method else ""
        print(f"      {method.upper()}: {score:.3f} {marker}")
    
    print(f"\n   âœ… Ã–NERILEN YÃ–NTEM: {best_method.upper()}")
    
    # Yorum
    if best_method == 'otsu':
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - Otsu thresholding histogram analizi ile optimal eÅŸik bulur")
        print(f"      - Equalization sonrasÄ± bimodal histogram â†’ Otsu iÃ§in ideal")
        print(f"      - Lezyon-arka plan ayrÄ±mÄ± net")
        print(f"      - TutarlÄ± sonuÃ§lar veriyor")
    elif best_method == 'global':
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - Sabit eÅŸik (127) tÃ¼m gÃ¶rÃ¼ntÃ¼ler iÃ§in Ã§alÄ±ÅŸmÄ±ÅŸ")
        print(f"      - Basit ve hÄ±zlÄ±")
        print(f"      - Ama optimal olmayabilir")
    else:  # adaptive
        print(f"\n   ðŸ’¬ YORUM:")
        print(f"      - Adaptive thresholding lokal varyasyonlarÄ± yakalamÄ±ÅŸ")
        print(f"      - Ä°Ã§ detaylar korunmuÅŸ")
        print(f"      - Ama bazÄ± gÃ¼rÃ¼ltÃ¼lÃ¼ bÃ¶lgeler oluÅŸabilir")
    
    # SeÃ§ilen yÃ¶ntemi kaydet
    for key in segmented_data:
        segmented_data[key]['recommended_method'] = best_method
        if best_method == 'global':
            segmented_data[key]['selected_binary'] = segmented_data[key]['binary_global']
        elif best_method == 'otsu':
            segmented_data[key]['selected_binary'] = segmented_data[key]['binary_otsu']
        else:  # adaptive
            segmented_data[key]['selected_binary'] = segmented_data[key]['binary_adaptive']
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 3 (THRESHOLDING) TAMAMLANDI!")
    print(f"ðŸ“Œ Ã–nerilen yÃ¶ntem: {best_method.upper()}")
    print("="*80)
    
    return segmented_data, best_method


# ==================== AÅžAMA 4.1: MORFOLOJÄ°K OPERATÃ–RLER ====================
def stage4_1_morphological_operations(segmented_data, num_samples=9, save_output=True):
    """
    AÅŸama 4.1: Morfolojik operatÃ¶rler ile binary maske temizleme
    
    Ä°ÅŸlemler:
    1. Opening (Erosion + Dilation) - KÃ¼Ã§Ã¼k gÃ¼rÃ¼ltÃ¼leri temizle
    2. Closing (Dilation + Erosion) - Delikleri doldur
    
    Kernel: Ellipse (lezyonlar yuvarlak)
    
    Args:
        segmented_data: AÅŸama 3'ten gelen binary maskeli dict
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: Morfoloji uygulanmÄ±ÅŸ maskeleri iÃ§eren dictionary
        tuple: SeÃ§ilen kernel (ÅŸekil, boyut)
    """
    print(f"\n{'='*80}")
    print("ðŸ”¬ AÅžAMA 4.1: MORFOLOJÄ°K OPERATÃ–RLER")
    print("="*80)
    print("\nðŸ“‹ Uygulanacak Ä°ÅŸlemler:")
    print("   1ï¸âƒ£  Opening (Erosion + Dilation)")
    print("      â†’ KÃ¼Ã§Ã¼k beyaz gÃ¼rÃ¼ltÃ¼leri temizler")
    print("      â†’ Lezyon dÄ±ÅŸÄ±ndaki noktalarÄ± siler")
    print("   2ï¸âƒ£  Closing (Dilation + Erosion)")
    print("      â†’ Lezyon iÃ§indeki delikleri doldurur")
    print("      â†’ Lezyon bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ saÄŸlar")
    print("\nðŸ”§ Kernel: ELLIPSE (lezyonlar yuvarlak/oval)")
    print("   Test edilecek boyutlar: 5x5, 7x7")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(segmented_data.keys())[:num_samples]
    
    # Kernel boyutlarÄ±nÄ± test et
    kernel_sizes = [5, 7]
    
    # GÃ¶rselleÅŸtirme iÃ§in hazÄ±rlÄ±k
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*3, figsize=(18, 12))
    fig.suptitle('AÅžAMA 4.1: Morfolojik OperatÃ¶rler (Opening + Closing)', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    morphed_data = {}
    morph_stats = {
        'original_components': [],
        'morphed_components_5': [],
        'morphed_components_7': []
    }
    
    # Ã–nce en iyi kernel boyutunu belirlemek iÃ§in istatistik topla
    for key in sample_keys[:9]:
        binary_mask = segmented_data[key]['selected_binary']
        
        # Orijinal bileÅŸen sayÄ±sÄ±
        num_labels_orig, _ = cv2.connectedComponents(binary_mask)
        morph_stats['original_components'].append(num_labels_orig - 1)  # -1: arka plan hariÃ§
        
        # Her kernel boyutu iÃ§in test
        for ksize in kernel_sizes:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))
            
            # Opening + Closing
            opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
            closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
            
            # BileÅŸen sayÄ±sÄ±
            num_labels, _ = cv2.connectedComponents(closed)
            if ksize == 5:
                morph_stats['morphed_components_5'].append(num_labels - 1)
            else:
                morph_stats['morphed_components_7'].append(num_labels - 1)
    
    # En iyi kernel boyutunu seÃ§
    # Hedef: BileÅŸen sayÄ±sÄ±nÄ± 1'e yaklaÅŸtÄ±rmak
    avg_comp_5 = np.mean(morph_stats['morphed_components_5'])
    avg_comp_7 = np.mean(morph_stats['morphed_components_7'])
    
    # 1'e yakÄ±nlÄ±k skoru
    score_5 = 1.0 / (1.0 + abs(avg_comp_5 - 1.0))
    score_7 = 1.0 / (1.0 + abs(avg_comp_7 - 1.0))
    
    best_kernel_size = 5 if score_5 >= score_7 else 7
    
    print(f"\nðŸ“Š Kernel Boyutu SeÃ§imi:")
    print(f"   Kernel 5x5: Ortalama {avg_comp_5:.1f} bileÅŸen (Skor: {score_5:.3f})")
    print(f"   Kernel 7x7: Ortalama {avg_comp_7:.1f} bileÅŸen (Skor: {score_7:.3f})")
    print(f"   âœ… SeÃ§ilen: {best_kernel_size}x{best_kernel_size}")
    
    # SeÃ§ilen kernel ile tÃ¼m gÃ¶rÃ¼ntÃ¼leri iÅŸle ve gÃ¶rselleÅŸtir
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (best_kernel_size, best_kernel_size))
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        binary_mask = segmented_data[key]['selected_binary']
        
        # Opening + Closing uygula
        opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
        
        # BileÅŸen sayÄ±larÄ±nÄ± hesapla
        num_orig, _ = cv2.connectedComponents(binary_mask)
        num_final, _ = cv2.connectedComponents(closed)
        
        # Veriyi kaydet
        morphed_data[key] = {
            'original_binary': binary_mask,
            'opened': opened,
            'final_morphed': closed,
            'rgb': segmented_data[key]['rgb'],
            'class': segmented_data[key]['class'],
            'kernel_size': best_kernel_size,
            'stats': {
                'components_before': num_orig - 1,
                'components_after': num_final - 1
            }
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Orijinal binary (sol)
        ax_orig = axes[row_idx, col_idx*3]
        ax_orig.imshow(binary_mask, cmap='gray')
        ax_orig.set_title(f'Binary\n{num_orig-1} bileÅŸen', fontsize=8)
        ax_orig.axis('off')
        
        # Opening sonrasÄ± (orta)
        ax_open = axes[row_idx, col_idx*3 + 1]
        ax_open.imshow(opened, cmap='gray')
        num_open, _ = cv2.connectedComponents(opened)
        ax_open.set_title(f'Opening\n{num_open-1} bileÅŸen', fontsize=8, color='blue')
        ax_open.axis('off')
        
        # Closing sonrasÄ± (saÄŸ)
        ax_close = axes[row_idx, col_idx*3 + 2]
        ax_close.imshow(closed, cmap='gray')
        color = 'green' if (num_final-1) <= 1 else 'orange' if (num_final-1) <= 3 else 'red'
        ax_close.set_title(f'Opening+Closing\n{num_final-1} bileÅŸen', fontsize=8, color=color)
        ax_close.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '06_morphology.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… GÃ¶rselleÅŸtirme kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # Ä°statistikler
    print(f"\nðŸ“Š Morfoloji Ä°statistikleri ({len(morphed_data)} Ã¶rnek):")
    
    components_before = [d['stats']['components_before'] for d in morphed_data.values()]
    components_after = [d['stats']['components_after'] for d in morphed_data.values()]
    
    print(f"\n   BileÅŸen SayÄ±sÄ± DeÄŸiÅŸimi:")
    print(f"      Ã–ncesi: Ortalama {np.mean(components_before):.1f} bileÅŸen")
    print(f"      SonrasÄ±: Ortalama {np.mean(components_after):.1f} bileÅŸen")
    
    # 1 bileÅŸenli gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±
    single_component = sum(1 for c in components_after if c == 1)
    print(f"\n   Tek BileÅŸen (Ä°deal):")
    print(f"      {single_component}/{len(components_after)} gÃ¶rÃ¼ntÃ¼ (%{single_component/len(components_after)*100:.1f})")
    
    # Yorum
    print(f"\nðŸ’¡ YORUM:")
    if np.mean(components_after) <= 1.5:
        print(f"      âœ… MÃ¼kemmel! Ã‡oÄŸu gÃ¶rÃ¼ntÃ¼ tek bileÅŸene indirildi")
        print(f"      â†’ Opening gÃ¼rÃ¼ltÃ¼leri baÅŸarÄ±yla temizledi")
        print(f"      â†’ Closing delikleri doldurdu")
    elif np.mean(components_after) <= 3:
        print(f"      âš ï¸  Ä°yi ama bazÄ± gÃ¶rÃ¼ntÃ¼lerde hala Ã§oklu bileÅŸen var")
        print(f"      â†’ CCL ile en bÃ¼yÃ¼k bileÅŸeni seÃ§eceÄŸiz")
    else:
        print(f"      âŒ Ã‡ok fazla bileÅŸen kaldÄ±")
        print(f"      â†’ Daha bÃ¼yÃ¼k kernel veya farklÄ± strateji gerekli")
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 4.1 TAMAMLANDI!")
    print(f"ðŸ“Œ KullanÄ±lan kernel: ELLIPSE {best_kernel_size}x{best_kernel_size}")
    print("="*80)
    
    return morphed_data, ('ellipse', best_kernel_size)


# ==================== AÅžAMA 4.2: CONNECTED COMPONENT LABELING (CCL) ====================
def stage4_2_connected_component_labeling(morphed_data, num_samples=9, save_output=True):
    """
    AÅŸama 4.2: Connected Component Labeling ve final ROI seÃ§imi
    
    Strateji:
    1. Her maskede baÄŸÄ±msÄ±z bileÅŸenleri bul (CCL)
    2. BileÅŸen sayÄ±sÄ±nÄ± analiz et
    3. EÄŸer birden fazla bileÅŸen varsa â†’ En bÃ¼yÃ¼ÄŸÃ¼nÃ¼ seÃ§
    4. Final ROI maskesi oluÅŸtur
    
    Args:
        morphed_data: AÅŸama 4.1'den gelen morfoloji uygulanmÄ±ÅŸ dict
        num_samples: GÃ¶rselleÅŸtirilecek Ã¶rnek sayÄ±sÄ±
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        dict: Final ROI maskeleri iÃ§eren dictionary
    """
    print(f"\n{'='*80}")
    print("ðŸ”¢ AÅžAMA 4.2: CONNECTED COMPONENT LABELING (CCL)")
    print("="*80)
    print("\nðŸ“‹ Ä°ÅŸlem AdÄ±mlarÄ±:")
    print("   1ï¸âƒ£  Her maskede baÄŸÄ±msÄ±z bileÅŸenleri tespit et")
    print("   2ï¸âƒ£  BileÅŸen sayÄ±sÄ±nÄ± analiz et")
    print("   3ï¸âƒ£  Strateji: En bÃ¼yÃ¼k bileÅŸeni seÃ§ (ana lezyon)")
    print("   4ï¸âƒ£  Final ROI maskesi oluÅŸtur")
    
    # Rastgele Ã¶rnekler seÃ§
    sample_keys = list(morphed_data.keys())[:num_samples]
    
    # GÃ¶rselleÅŸtirme: Orijinal, CCL renkli, Final ROI
    rows = 3
    cols = 3
    fig, axes = plt.subplots(rows, cols*3, figsize=(18, 12))
    fig.suptitle('AÅžAMA 4.2: Connected Component Labeling - Final ROI SeÃ§imi', 
                 fontsize=16, fontweight='bold', y=0.995)
    
    final_data = {}
    ccl_stats = {
        'num_components': [],
        'selected_areas': [],
        'removed_components': []
    }
    
    for idx, key in enumerate(sample_keys):
        if idx >= rows * cols:
            break
        
        morphed_mask = morphed_data[key]['final_morphed']
        
        # Connected Components uygula
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(morphed_mask, connectivity=8)
        
        # Arka plan (label 0) hariÃ§
        num_components = num_labels - 1
        ccl_stats['num_components'].append(num_components)
        
        # En bÃ¼yÃ¼k bileÅŸeni seÃ§ (arka plan hariÃ§)
        if num_components > 0:
            # Arka plan (0) hariÃ§ alanlarÄ± al
            areas = stats[1:, cv2.CC_STAT_AREA]
            largest_idx = np.argmax(areas) + 1  # +1: arka plan offset
            
            # Final ROI maskesi: Sadece en bÃ¼yÃ¼k bileÅŸen
            final_roi = (labels == largest_idx).astype(np.uint8) * 255
            
            selected_area = areas[largest_idx - 1]
            removed_count = num_components - 1
            
            ccl_stats['selected_areas'].append(selected_area)
            ccl_stats['removed_components'].append(removed_count)
        else:
            # HiÃ§ bileÅŸen yoksa (boÅŸ maske)
            final_roi = np.zeros_like(morphed_mask)
            selected_area = 0
            removed_count = 0
            ccl_stats['selected_areas'].append(0)
            ccl_stats['removed_components'].append(0)
        
        # Veriyi kaydet
        final_data[key] = {
            'morphed_mask': morphed_mask,
            'labels': labels,
            'num_components': num_components,
            'final_roi': final_roi,
            'selected_area': selected_area,
            'removed_components': removed_count,
            'rgb': morphed_data[key]['rgb'],
            'class': morphed_data[key]['class']
        }
        
        # GÃ¶rselleÅŸtirme
        row_idx = idx // cols
        col_idx = idx % cols
        
        # Morfoloji sonrasÄ± (sol)
        ax_morph = axes[row_idx, col_idx*3]
        ax_morph.imshow(morphed_mask, cmap='gray')
        ax_morph.set_title(f'Morfoloji\n{num_components} bileÅŸen', fontsize=8)
        ax_morph.axis('off')
        
        # CCL renkli (orta)
        ax_ccl = axes[row_idx, col_idx*3 + 1]
        # Renkli label gÃ¶rÃ¼ntÃ¼sÃ¼ oluÅŸtur
        label_hue = np.uint8(179 * labels / np.max(labels)) if np.max(labels) > 0 else np.zeros_like(labels, dtype=np.uint8)
        label_hue[labels == 0] = 0  # Arka plan siyah
        
        # HSV'ye Ã§evir (renklendirme iÃ§in)
        blank_channel = np.ones_like(label_hue) * 255
        label_img = cv2.merge([label_hue, blank_channel, blank_channel])
        label_img_rgb = cv2.cvtColor(label_img, cv2.COLOR_HSV2RGB)
        label_img_rgb[labels == 0] = 0  # Arka plan siyah
        
        ax_ccl.imshow(label_img_rgb)
        color = 'green' if num_components == 1 else 'orange' if num_components <= 3 else 'red'
        ax_ccl.set_title(f'CCL Renkli\n{num_components} bileÅŸen', fontsize=8, color=color)
        ax_ccl.axis('off')
        
        # Final ROI (saÄŸ)
        ax_roi = axes[row_idx, col_idx*3 + 2]
        ax_roi.imshow(final_roi, cmap='gray')
        ax_roi.set_title(f'Final ROI\nAlan: {selected_area} px\nâ†“ {removed_count} bileÅŸen', 
                        fontsize=8, color='green')
        ax_roi.axis('off')
    
    plt.tight_layout()
    
    if save_output:
        output_file = '07_ccl_final_roi.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"\nâœ… GÃ¶rselleÅŸtirme kaydedildi: {output_file}")
    
    plt.show()
    plt.close()
    
    # CCL istatistikleri
    print(f"\nðŸ“Š CCL Ä°statistikleri ({len(ccl_stats['num_components'])} Ã¶rnek):")
    
    components_counts = np.array(ccl_stats['num_components'])
    
    print(f"\n   BileÅŸen SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±:")
    for n in range(1, max(components_counts) + 1 if len(components_counts) > 0 else 1):
        count = np.sum(components_counts == n)
        if count > 0:
            marker = "âœ…" if n == 1 else "âš ï¸" if n <= 3 else "âŒ"
            print(f"      {marker} {n} bileÅŸen: {count} gÃ¶rÃ¼ntÃ¼ (%{count/len(components_counts)*100:.1f})")
    
    print(f"\n   ROI Alan Ä°statistikleri:")
    if len(ccl_stats['selected_areas']) > 0:
        print(f"      Ortalama: {np.mean(ccl_stats['selected_areas']):.0f} piksel")
        print(f"      Min: {np.min(ccl_stats['selected_areas']):.0f} piksel")
        print(f"      Max: {np.max(ccl_stats['selected_areas']):.0f} piksel")
    
    print(f"\n   Temizleme Ã–zeti:")
    total_removed = np.sum(ccl_stats['removed_components'])
    print(f"      Toplam {total_removed} kÃ¼Ã§Ã¼k bileÅŸen temizlendi")
    
    # Yorum
    print(f"\nðŸ’¡ YORUM:")
    single_roi_count = np.sum(components_counts == 1)
    single_roi_percent = single_roi_count / len(components_counts) * 100 if len(components_counts) > 0 else 0
    
    if single_roi_percent >= 80:
        print(f"      âœ… MÃœKEMMEL! %{single_roi_percent:.0f} gÃ¶rÃ¼ntÃ¼de tek ROI")
        print(f"      â†’ Ã‡oÄŸu gÃ¶rÃ¼ntÃ¼ zaten temizdi")
        print(f"      â†’ Segmentasyon pipeline baÅŸarÄ±lÄ±")
    elif single_roi_percent >= 60:
        print(f"      âœ… Ä°YÄ°! %{single_roi_percent:.0f} gÃ¶rÃ¼ntÃ¼de tek ROI")
        print(f"      â†’ DiÄŸerlerinde en bÃ¼yÃ¼k bileÅŸen seÃ§ildi")
        print(f"      â†’ Kabul edilebilir sonuÃ§")
    else:
        print(f"      âš ï¸  ORTA: Sadece %{single_roi_percent:.0f} gÃ¶rÃ¼ntÃ¼de tek ROI")
        print(f"      â†’ Ã‡ok parÃ§alÄ± lezyonlar var")
        print(f"      â†’ En bÃ¼yÃ¼k bileÅŸen stratejisi uygulandÄ±")
    
    if total_removed > 0:
        print(f"\n   ðŸ§¹ Temizlik:")
        print(f"      â†’ {total_removed} kÃ¼Ã§Ã¼k bileÅŸen (gÃ¼rÃ¼ltÃ¼/artefakt) kaldÄ±rÄ±ldÄ±")
        print(f"      â†’ Ana lezyon korundu")
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 4.2 TAMAMLANDI!")
    print(f"ðŸ“Œ Strateji: En bÃ¼yÃ¼k bileÅŸen seÃ§imi")
    print("="*80)
    
    return final_data


# ==================== AÅžAMA 5: Ã–ZNÄ°TELÄ°K Ã‡IKARIMI ====================
from scipy import stats as scipy_stats
from skimage.feature import graycomatrix, graycoprops
from skimage.measure import regionprops

def extract_first_order_features(gray_img, roi_mask):
    """
    First-order (Ä°statistiksel) Ã¶znitelikler
    
    Args:
        gray_img: Grayscale gÃ¶rÃ¼ntÃ¼
        roi_mask: Binary ROI maskesi (255 = lezyon)
        
    Returns:
        dict: Ä°statistiksel Ã¶znitelikler
    """
    # ROI iÃ§indeki pikseller
    roi_pixels = gray_img[roi_mask == 255]
    
    if len(roi_pixels) == 0:
        return {f'first_order_{k}': 0.0 for k in ['mean', 'std', 'variance', 'min', 'max', 
                                                     'median', 'skewness', 'kurtosis', 'entropy', 'energy']}
    
    features = {
        'first_order_mean': float(np.mean(roi_pixels)),
        'first_order_std': float(np.std(roi_pixels)),
        'first_order_variance': float(np.var(roi_pixels)),
        'first_order_min': float(np.min(roi_pixels)),
        'first_order_max': float(np.max(roi_pixels)),
        'first_order_median': float(np.median(roi_pixels)),
        'first_order_skewness': float(scipy_stats.skew(roi_pixels)),
        'first_order_kurtosis': float(scipy_stats.kurtosis(roi_pixels)),
        'first_order_entropy': float(scipy_stats.entropy(np.histogram(roi_pixels, bins=256)[0] + 1e-10)),
        'first_order_energy': float(np.sum(roi_pixels.astype(np.float64) ** 2))
    }
    
    return features


def extract_shape_features(roi_mask):
    """
    2D Shape (Åžekil) Ã¶znitelikleri
    
    Args:
        roi_mask: Binary ROI maskesi
        
    Returns:
        dict: Åžekil Ã¶znitelikleri
    """
    # Contour bul
    contours, _ = cv2.findContours(roi_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return {f'shape_{k}': 0.0 for k in ['area', 'perimeter', 'circularity', 'eccentricity', 
                                             'solidity', 'extent', 'major_axis', 'minor_axis', 
                                             'aspect_ratio', 'convex_area', 'equivalent_diameter', 'compactness']}
    
    cnt = contours[0]
    
    # Temel Ã¶lÃ§Ã¼ler
    area = cv2.contourArea(cnt)
    perimeter = cv2.arcLength(cnt, True)
    
    # Circularity
    circularity = (4 * np.pi * area / (perimeter ** 2)) if perimeter > 0 else 0
    
    # Compactness (alternatif circularity)
    compactness = (perimeter ** 2 / area) if area > 0 else 0
    
    # Convex hull
    hull = cv2.convexHull(cnt)
    convex_area = cv2.contourArea(hull)
    solidity = (area / convex_area) if convex_area > 0 else 0
    
    # Bounding box
    x, y, w, h = cv2.boundingRect(cnt)
    extent = (area / (w * h)) if (w * h) > 0 else 0
    
    # Ellipse fitting (major/minor axis, eccentricity)
    if len(cnt) >= 5:  # fitEllipse en az 5 nokta gerektirir
        try:
            ellipse = cv2.fitEllipse(cnt)
            (center_x, center_y), (MA, ma), angle = ellipse
            major_axis = max(MA, ma)
            minor_axis = min(MA, ma)
            aspect_ratio = major_axis / minor_axis if minor_axis > 0 else 0
            eccentricity = np.sqrt(1 - (minor_axis / major_axis) ** 2) if major_axis > 0 else 0
        except:
            major_axis = minor_axis = aspect_ratio = eccentricity = 0
    else:
        major_axis = minor_axis = aspect_ratio = eccentricity = 0
    
    # Equivalent diameter
    equivalent_diameter = np.sqrt(4 * area / np.pi) if area > 0 else 0
    
    features = {
        'shape_area': float(area),
        'shape_perimeter': float(perimeter),
        'shape_circularity': float(circularity),
        'shape_compactness': float(compactness),
        'shape_eccentricity': float(eccentricity),
        'shape_solidity': float(solidity),
        'shape_extent': float(extent),
        'shape_major_axis': float(major_axis),
        'shape_minor_axis': float(minor_axis),
        'shape_aspect_ratio': float(aspect_ratio),
        'shape_convex_area': float(convex_area),
        'shape_equivalent_diameter': float(equivalent_diameter)
    }
    
    return features


def extract_glcm_features(gray_img, roi_mask, distances=[1, 2, 3], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=16):
    """
    GLCM (Texture) Ã¶znitelikleri
    
    Args:
        gray_img: Grayscale gÃ¶rÃ¼ntÃ¼
        roi_mask: Binary ROI maskesi
        distances: GLCM uzaklÄ±klarÄ±
        angles: GLCM aÃ§Ä±larÄ±
        levels: Gri seviye sayÄ±sÄ± (quantization)
        
    Returns:
        dict: GLCM Ã¶znitelikleri
    """
    # ROI iÃ§indeki bÃ¶lgeyi kes
    roi_pixels = gray_img[roi_mask == 255]
    
    if len(roi_pixels) < 10:
        return {f'glcm_{k}': 0.0 for k in ['contrast', 'dissimilarity', 'homogeneity', 
                                            'energy', 'correlation', 'ASM']}
    
    # ROI'yi quantize et (256 â†’ levels)
    roi_quantized = (roi_pixels / 256.0 * levels).astype(np.uint8)
    roi_quantized = np.clip(roi_quantized, 0, levels - 1)
    
    # GLCM iÃ§in 2D gÃ¶rÃ¼ntÃ¼ gerekli, ROI'yi yeniden ÅŸekillendir
    # Basit bir yaklaÅŸÄ±m: ROI'yi kare matrise dÃ¶nÃ¼ÅŸtÃ¼r
    side_length = int(np.sqrt(len(roi_quantized))) + 1
    roi_padded = np.zeros((side_length, side_length), dtype=np.uint8)
    roi_padded.flat[:len(roi_quantized)] = roi_quantized
    
    # GLCM hesapla
    try:
        glcm = graycomatrix(roi_padded, distances=distances, angles=angles, 
                           levels=levels, symmetric=True, normed=True)
        
        # GLCM Ã¶zelliklerini hesapla
        contrast = graycoprops(glcm, 'contrast').mean()
        dissimilarity = graycoprops(glcm, 'dissimilarity').mean()
        homogeneity = graycoprops(glcm, 'homogeneity').mean()
        energy = graycoprops(glcm, 'energy').mean()
        correlation = graycoprops(glcm, 'correlation').mean()
        ASM = graycoprops(glcm, 'ASM').mean()
        
        features = {
            'glcm_contrast': float(contrast),
            'glcm_dissimilarity': float(dissimilarity),
            'glcm_homogeneity': float(homogeneity),
            'glcm_energy': float(energy),
            'glcm_correlation': float(correlation),
            'glcm_ASM': float(ASM)
        }
    except:
        features = {f'glcm_{k}': 0.0 for k in ['contrast', 'dissimilarity', 'homogeneity', 
                                                 'energy', 'correlation', 'ASM']}
    
    return features


def stage5_feature_extraction(df, final_data_samples, save_output=True):
    """
    AÅŸama 5: TÃœM veri setinden Ã¶znitelik Ã§Ä±karÄ±mÄ±
    
    Bu aÅŸama TÃœM gÃ¶rÃ¼ntÃ¼leri iÅŸleyecek (sadece Ã¶rnekler deÄŸil)
    
    Args:
        df: GÃ¶rÃ¼ntÃ¼ bilgilerini iÃ§eren DataFrame (tÃ¼m veri seti)
        final_data_samples: AÅŸama 4.2'den gelen 9 Ã¶rnek (referans iÃ§in)
        save_output: Ã‡Ä±ktÄ±yÄ± kaydetmek iÃ§in True
        
    Returns:
        pd.DataFrame: Ã–znitelik tablosu
    """
    print(f"\n{'='*80}")
    print("ðŸ“Š AÅžAMA 5: Ã–ZNÄ°TELÄ°K Ã‡IKARIMI")
    print("="*80)
    print(f"\nâš ï¸  DÄ°KKAT: Bu aÅŸama TÃœM veri setini iÅŸleyecek!")
    print(f"   Toplam gÃ¶rÃ¼ntÃ¼: {len(df)}")
    print(f"   Tahmini sÃ¼re: ~{len(df) * 2 / 60:.1f} dakika")
    print(f"\nðŸ“‹ Ã‡Ä±karÄ±lacak Ã–znitelikler:")
    print(f"   1ï¸âƒ£  First-Order (Ä°statistiksel): 10 Ã¶zellik")
    print(f"   2ï¸âƒ£  2D Shape (Åžekil): 12 Ã¶zellik")
    print(f"   3ï¸âƒ£  GLCM (Texture): 6 Ã¶zellik")
    print(f"   ðŸ“Œ TOPLAM: 28 Ã¶znitelik + metadata")
    
    # TÃ¼m pipeline'Ä± her gÃ¶rÃ¼ntÃ¼ iÃ§in Ã§alÄ±ÅŸtÄ±r
    feature_list = []
    errors = []
    
    print(f"\nðŸ”„ Ä°ÅŸleme baÅŸlÄ±yor...")
    
    for idx, row in df.iterrows():
        try:
            # Progress indicator
            if (idx + 1) % 100 == 0:
                print(f"   Ä°ÅŸlenen: {idx + 1}/{len(df)} (%{(idx+1)/len(df)*100:.1f})")
            
            # 1. GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
            img = cv2.imread(row['filepath'])
            if img is None:
                raise ValueError("GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi")
            
            # 2. RGB â†’ Grayscale
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
            
            # 3. Crop (basit - merkez crop) - BOYUT KONTROLÃœ EKLE
            h, w = img_gray.shape
            margin = min(10, h // 20, w // 20)  # GÃ¶rÃ¼ntÃ¼ Ã§ok kÃ¼Ã§Ã¼kse margin'i azalt
            
            if h > 2 * margin and w > 2 * margin:
                img_cropped = img_gray[margin:h-margin, margin:w-margin]
            else:
                img_cropped = img_gray  # Ã‡ok kÃ¼Ã§Ã¼kse crop yapma
            
            # 4. Equalization
            img_eq = cv2.equalizeHist(img_cropped)
            
            # 5. Median Blur
            img_blur = cv2.medianBlur(img_eq, 5)
            
            # 6. Otsu Thresholding
            _, binary = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # 7. Morfoloji
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
            closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
            
            # 8. CCL - En bÃ¼yÃ¼k bileÅŸeni seÃ§
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(closed, connectivity=8)
            
            if num_labels > 1:
                areas = stats[1:, cv2.CC_STAT_AREA]
                largest_idx = np.argmax(areas) + 1
                final_roi = (labels == largest_idx).astype(np.uint8) * 255
            else:
                final_roi = np.zeros_like(closed)
            
            # 9. Ã–znitelik Ã§Ä±karÄ±mÄ±
            # Ã–NEMLÄ°: img_cropped ve final_roi aynÄ± boyutta!
            first_order_feats = extract_first_order_features(img_cropped, final_roi)
            shape_feats = extract_shape_features(final_roi)
            glcm_feats = extract_glcm_features(img_cropped, final_roi)
            
            # Metadata
            metadata = {
                'image_id': row['filename'],
                'class': row['class'],
                'width': row['width'],
                'height': row['height'],
                'roi_area': shape_feats['shape_area']
            }
            
            # TÃ¼m Ã¶zellikleri birleÅŸtir
            all_features = {**metadata, **first_order_feats, **shape_feats, **glcm_feats}
            feature_list.append(all_features)
            
        except Exception as e:
            errors.append({'filename': row['filename'], 'error': str(e)})
            if len(errors) <= 10:  # Ä°lk 10 hatayÄ± gÃ¶ster
                print(f"\n   âš ï¸  Hata ({row['filename']}): {e}")
    
    print(f"\nâœ… Ä°ÅŸlem tamamlandÄ±!")
    print(f"   BaÅŸarÄ±lÄ±: {len(feature_list)}/{len(df)}")
    if errors:
        print(f"   âš ï¸  Hatalar: {len(errors)}")
        if len(errors) > 10:
            print(f"   (Ä°lk 10 hata gÃ¶sterildi, toplam {len(errors)} hata)")
    
    # DataFrame oluÅŸtur
    features_df = pd.DataFrame(feature_list)
    
    # CSV olarak kaydet
    if save_output and len(features_df) > 0:
        csv_file = 'features.csv'
        features_df.to_csv(csv_file, index=False)
        print(f"\nâœ… Ã–znitelik tablosu kaydedildi: {csv_file}")
        print(f"   SatÄ±r sayÄ±sÄ±: {len(features_df)}")
        print(f"   SÃ¼tun sayÄ±sÄ±: {len(features_df.columns)}")
    
    # Ã–zet istatistikler
    if len(features_df) > 0:
        print(f"\nðŸ“Š Ã–znitelik Tablosu Ã–zeti:")
        print(f"   Toplam gÃ¶rÃ¼ntÃ¼: {len(features_df)}")
        print(f"   Toplam Ã¶znitelik: {len(features_df.columns) - 5}")  # metadata hariÃ§
        print(f"   SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
        print(features_df['class'].value_counts())
        
        print(f"\nðŸ“‹ Ä°lk 5 satÄ±r:")
        print(features_df.head())
        
        # Ä°statistikler
        print(f"\nðŸ“ˆ Ã–znitelik Ä°statistikleri (ilk 10 sÃ¼tun):")
        print(features_df.iloc[:, :10].describe())
    
    print(f"\n{'='*80}")
    print("âœ… AÅžAMA 5 TAMAMLANDI!")
    print("="*80)
    
    return features_df


# ==================== ANA PROGRAM ====================
if __name__ == "__main__":
    
    # Veri seti kontrolÃ¼
    if not os.path.exists(DATA_PATH):
        print(f"\nâŒ HATA: '{DATA_PATH}' klasÃ¶rÃ¼ bulunamadÄ±!")
        print("\nðŸ“ Ã‡Ã¶zÃ¼mler:")
        print("   1. ISIC klasÃ¶rÃ¼nÃ¼ Python dosyasÄ±yla aynÄ± dizine koyun")
        print(f"   2. Veya kodda DATA_PATH deÄŸiÅŸkenini tam yol olarak gÃ¼ncelleyin")
        print(f"\nðŸ’¡ Åžu an Ã§alÄ±ÅŸÄ±lan dizin: {os.getcwd()}")
        print(f"\nðŸ“‹ Bu dizindeki klasÃ¶rler:")
        for item in os.listdir('.'):
            if os.path.isdir(item):
                print(f"   ðŸ“ {item}/")
        exit(1)
    
    # Veri setini yÃ¼kle
    df = load_image_dataset(DATA_PATH)
    
    if len(df) == 0:
        print("\nâŒ HATA: HiÃ§ gÃ¶rÃ¼ntÃ¼ bulunamadÄ±!")
        exit(1)
    
    # ==================== AÅžAMA 1: RGB â†’ GRAYSCALE ====================
    print("\n" + "="*80)
    print("ðŸš€ AÅžAMA 1 BAÅžLIYOR...")
    print("="*80)
    
    grayscale_data = stage1_rgb_to_grayscale(df, num_samples=9, save_output=True)
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 1 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(grayscale_data)} gÃ¶rÃ¼ntÃ¼ iÅŸlendi")
    print(f"âœ… Ã‡Ä±ktÄ±: 01_rgb_vs_grayscale.png")
    print(f"\nðŸ’¡ KONTROL: Grayscale dÃ¶nÃ¼ÅŸÃ¼mÃ¼ baÅŸarÄ±lÄ± mÄ±?")
    print(f"   - RGB ve Grayscale karÅŸÄ±laÅŸtÄ±rmasÄ±na bakÄ±n")
    print(f"   - Lezyon bÃ¶lgeleri gri tonlamada gÃ¶rÃ¼nÃ¼yor mu?")
    print(f"   - Detay kaybÄ± var mÄ±?")
    
    # ==================== AÅžAMA 2.1: DÄ°NAMÄ°K CROP ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 2.1 BAÅžLIYOR...")
    print("="*80)
    
    cropped_data = stage2_1_dynamic_crop(grayscale_data, num_samples=9, save_output=True)
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 2.1 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(cropped_data)} gÃ¶rÃ¼ntÃ¼ kÄ±rpÄ±ldÄ±")
    print(f"âœ… Ã‡Ä±ktÄ±: 02_dynamic_crop.png")
    print(f"\nðŸ’¡ KONTROL: Dinamik kÄ±rpma baÅŸarÄ±lÄ± mÄ±?")
    print(f"   - KÄ±rmÄ±zÄ± Ã§erÃ§eve ilgi alanÄ±nÄ± doÄŸru mu kapsÄ±yor?")
    print(f"   - Lezyon bÃ¶lgesi kayboldu mu?")
    print(f"   - Arka plan gÃ¼rÃ¼ltÃ¼leri temizlendi mi?")
    print(f"   - KÄ±rpma oranÄ± mantÄ±klÄ± mÄ±?")
    
    # ==================== AÅžAMA 2.2: KONTRAST Ä°YÄ°LEÅžTÄ°RME ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 2.2 BAÅžLIYOR...")
    print("="*80)
    
    enhanced_data, recommendation = stage2_2_contrast_enhancement(
        cropped_data, num_samples=9, save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 2.2 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(enhanced_data)} gÃ¶rÃ¼ntÃ¼ iÅŸlendi")
    print(f"âœ… Ä°ki yÃ¶ntem karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±:")
    print(f"   - Kontrast Germe (Stretching)")
    print(f"   - Histogram EÅŸitleme (Equalization)")
    print(f"âœ… Ã‡Ä±ktÄ±lar:")
    print(f"   - 03_contrast_comparison.png (yan yana karÅŸÄ±laÅŸtÄ±rma)")
    print(f"   - 03_histogram_analysis.png (histogram grafikleri)")
    print(f"\nðŸŽ¯ OTOMATÄ°K Ã–NERÄ°: {recommendation.upper()}")
    print(f"\nðŸ’¡ KONTROL:")
    print(f"   - Hangi yÃ¶ntem lezyon-arka plan kontrastÄ±nÄ± daha iyi artÄ±rmÄ±ÅŸ?")
    print(f"   - Detay kaybÄ± var mÄ±?")
    print(f"   - Histogramlara bakÄ±n - daÄŸÄ±lÄ±m nasÄ±l?")
    print(f"   - Otomatik Ã¶neriye katÄ±lÄ±yor musunuz?")
    
    # ==================== AÅžAMA 2.3: GÃœRÃœLTÃœ AZALTMA ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 2.3 BAÅžLIYOR...")
    print("="*80)
    
    blurred_data, best_kernel = stage2_3_noise_reduction(
        enhanced_data, 
        kernel_sizes=[3, 5, 7],
        num_samples=9, 
        save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 2.3 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(blurred_data)} gÃ¶rÃ¼ntÃ¼ iÅŸlendi")
    print(f"âœ… Median Blur uygulandÄ±")
    print(f"âœ… 3 farklÄ± kernel boyutu test edildi: 3x3, 5x5, 7x7")
    print(f"âœ… Ã‡Ä±ktÄ±: 04_median_blur_comparison.png")
    print(f"\nðŸŽ¯ Ã–NERILEN KERNEL: {best_kernel}x{best_kernel}")
    print(f"\nðŸ’¡ KONTROL:")
    print(f"   - GÃ¼rÃ¼ltÃ¼ler temizlendi mi?")
    print(f"   - Lezyon kenarlarÄ± korundu mu?")
    print(f"   - Hangi kernel boyutu en iyi?")
    print(f"   - AÅŸÄ±rÄ± yumuÅŸatma var mÄ±?")
    
    # ==================== AÅžAMA 3: THRESHOLDING SEGMENTASYON ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 3 BAÅžLIYOR...")
    print("="*80)
    
    segmented_data, best_threshold_method = stage3_thresholding_segmentation(
        blurred_data,
        num_samples=9,
        save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 3 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(segmented_data)} gÃ¶rÃ¼ntÃ¼ segmente edildi")
    print(f"âœ… 3 threshold yÃ¶ntemi karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±:")
    print(f"   - Global Thresholding (T=127)")
    print(f"   - Otsu Thresholding (otomatik)")
    print(f"   - Adaptive Thresholding (lokal)")
    print(f"âœ… Ã‡Ä±ktÄ±: 05_threshold_comparison.png")
    print(f"\nðŸŽ¯ Ã–NERILEN YÃ–NTEM: {best_threshold_method.upper()}")
    print(f"\nðŸ’¡ KONTROL:")
    print(f"   - Binary maskeler doÄŸru mu?")
    print(f"   - Lezyon beyaz, arka plan siyah mÄ±?")
    print(f"   - Hangi yÃ¶ntem en temiz maske Ã¼retmiÅŸ?")
    print(f"   - Lezyon bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korunmuÅŸ mu (tek parÃ§a)?")
    
    # ==================== AÅžAMA 4.1: MORFOLOJÄ°K OPERATÃ–RLER ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 4.1 BAÅžLIYOR...")
    print("="*80)
    
    morphed_data, kernel_info = stage4_1_morphological_operations(
        segmented_data,
        num_samples=9,
        save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 4.1 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(morphed_data)} gÃ¶rÃ¼ntÃ¼ iÅŸlendi")
    print(f"âœ… Morfolojik operatÃ¶rler uygulandÄ±:")
    print(f"   - Opening (gÃ¼rÃ¼ltÃ¼ temizleme)")
    print(f"   - Closing (delik doldurma)")
    print(f"âœ… Kernel: {kernel_info[0].upper()} {kernel_info[1]}x{kernel_info[1]}")
    print(f"âœ… Ã‡Ä±ktÄ±: 06_morphology.png")
    print(f"\nðŸ’¡ KONTROL:")
    print(f"   - KÃ¼Ã§Ã¼k gÃ¼rÃ¼ltÃ¼ler temizlendi mi?")
    print(f"   - Lezyon iÃ§indeki delikler doldu mu?")
    print(f"   - BileÅŸen sayÄ±sÄ± azaldÄ± mÄ±?")
    
    # ==================== AÅžAMA 4.2: CONNECTED COMPONENT LABELING ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 4.2 BAÅžLIYOR...")
    print("="*80)
    
    final_data = stage4_2_connected_component_labeling(
        morphed_data,
        num_samples=9,
        save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸ“‹ AÅžAMA 4.2 SONUÃ‡ Ã–ZETÄ°")
    print("="*80)
    print(f"âœ… {len(final_data)} gÃ¶rÃ¼ntÃ¼ iÃ§in final ROI oluÅŸturuldu")
    print(f"âœ… Connected Component Labeling uygulandÄ±")
    print(f"âœ… Strateji: En bÃ¼yÃ¼k bileÅŸen seÃ§imi")
    print(f"âœ… Ã‡Ä±ktÄ±lar:")
    print(f"   - 07_ccl_final_roi.png (renkli CCL + final ROI)")
    print(f"\nðŸ’¡ KONTROL:")
    print(f"   - Her gÃ¶rÃ¼ntÃ¼de tek ROI var mÄ±?")
    print(f"   - En bÃ¼yÃ¼k bileÅŸen doÄŸru seÃ§ilmiÅŸ mi?")
    print(f"   - Final ROI lezyon bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ koruyor mu?")
    
    print(f"\n{'='*80}")
    print("ðŸŽ‰ SEGMENTa SYON TAMAMLANDI! (AÅžAMA 1-4)")
    print("="*80)
    print("\nâœ… Tamamlanan tÃ¼m adÄ±mlar:")
    print("   AÅžAMA 1: RGB â†’ Grayscale")
    print("   AÅžAMA 2.1: Dinamik Crop")
    print("   AÅžAMA 2.2: Kontrast Ä°yileÅŸtirme (Equalization)")
    print("   AÅžAMA 2.3: GÃ¼rÃ¼ltÃ¼ Azaltma (Median Blur)")
    print("   AÅžAMA 3: Thresholding (Otsu)")
    print("   AÅžAMA 4.1: Morfolojik OperatÃ¶rler")
    print("   AÅžAMA 4.2: Connected Component Labeling")
    print("\nðŸ“Š Ã‡Ä±ktÄ±lar:")
    print("   1. 01_rgb_vs_grayscale.png")
    print("   2. 02_dynamic_crop.png")
    print("   3. 03_contrast_comparison.png")
    print("   4. 03_histogram_analysis.png")
    print("   5. 04_median_blur_comparison.png")
    print("   6. 05_threshold_comparison.png")
    print("   7. 06_morphology.png")
    print("   8. 07_ccl_final_roi.png")
    print("\nðŸŽ¯ Sonraki adÄ±m: AÅžAMA 5 - Ã–ZNÄ°TELÄ°K Ã‡IKARIMI")
    print("   â†’ First-order features (istatistiksel)")
    print("   â†’ 2D Shape features (ÅŸekil)")
    print("   â†’ GLCM features (texture)")
    print("   â†’ Feature CSV oluÅŸturma")
    print("\n" + "="*80)
    
    # ==================== AÅžAMA 5: Ã–ZNÄ°TELÄ°K Ã‡IKARIMI ====================
    print(f"\n{'='*80}")
    print("ðŸš€ AÅžAMA 5 BAÅžLIYOR (SON AÅžAMA)...")
    print("="*80)
    print("\nâš ï¸  Ã–NEMLÄ°: Bu aÅŸama uzun sÃ¼rebilir!")
    print("   TÃ¼m veri seti iÅŸlenecek...")
    
    features_df = stage5_feature_extraction(
        df, 
        final_data,
        save_output=True
    )
    
    print(f"\n{'='*80}")
    print("ðŸŽŠ TÃœM PROJE TAMAMLANDI!")
    print("="*80)
    print("\nâœ… BAÅžARILI AÅžAMALAR:")
    print("   âœ… AÅžAMA 1: RGB â†’ Grayscale")
    print("   âœ… AÅžAMA 2: Pre-Processing (Crop, Kontrast, Blur)")
    print("   âœ… AÅžAMA 3: Thresholding Segmentasyon")
    print("   âœ… AÅžAMA 4: Post-Processing (Morfoloji, CCL)")
    print("   âœ… AÅžAMA 5: Ã–znitelik Ã‡Ä±karÄ±mÄ±")
    print("\nðŸ“Š FINAL Ã‡IKTILAR:")
    print("   ðŸ“ GÃ¶rselleÅŸtirmeler:")
    print("      - 01_rgb_vs_grayscale.png")
    print("      - 02_dynamic_crop.png")
    print("      - 03_contrast_comparison.png")
    print("      - 03_histogram_analysis.png")
    print("      - 04_median_blur_comparison.png")
    print("      - 05_threshold_comparison.png")
    print("      - 06_morphology.png")
    print("      - 07_ccl_final_roi.png")
    print("\n   ðŸ“„ Ã–znitelik Tablosu:")
    print(f"      - features.csv ({len(features_df)} gÃ¶rÃ¼ntÃ¼, {len(features_df.columns)} sÃ¼tun)")
    print("\nðŸŽ¯ Ã–ZNÄ°TELÄ°K TABLOSU Ä°Ã‡ERÄ°ÄžÄ°:")
    print(f"   - Metadata: image_id, class, width, height, roi_area")
    print(f"   - First-Order: 10 istatistiksel Ã¶zellik")
    print(f"   - Shape: 12 ÅŸekil Ã¶zelliÄŸi")
    print(f"   - GLCM: 6 texture Ã¶zelliÄŸi")
    print(f"   - TOPLAM: {len(features_df.columns)} sÃ¼tun")
    print("\nðŸ“Œ KULLANIM:")
    print("   Bu CSV dosyasÄ±nÄ± makine Ã¶ÄŸrenmesi modellerinde kullanabilirsiniz!")
    print("   - SÄ±nÄ±flandÄ±rma (classification)")
    print("   - KÃ¼meleme (clustering)")
    print("   - Ã–znitelik seÃ§imi (feature selection)")
    print("\n" + "="*80)
    print("ðŸŽ‰ PROJE BAÅžARIYLA TAMAMLANDI! ðŸŽ‰")
    print("="*80)
